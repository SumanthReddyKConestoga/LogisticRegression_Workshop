# Logistic Regression Workshop â€” Spotify Tracks (Explicit vs Nonâ€‘Explicit)

A clean, **Weekâ€‘6â€‘aligned** notebook that demonstrates how to frame a real dataset as a **probabilistic binary classification** problem using **Logistic Regression** â€” with **presentationâ€‘ready EDA**, **advanced evaluation visuals**, and **crisp talking points**.

---

## Business framing (Why this matters) ğŸ¯
In real products, we rarely want only a hard **Yes/No**. We want **risk scores** (probabilities) so we can:
- tune thresholds for different business contexts (e.g., â€œbe stricter for kids modeâ€),
- measure performance fairly under class imbalance,
- explain decisions to stakeholders.

This workshop turns Spotify track attributes into a model that outputs:
> **P(track is explicit)**

---

## What you will see in the notebook âœ…
### 1) Data loading + sanity checks
- shape, missing values, data types
- basic distribution checks for numeric features

### 2) Strong EDA visuals (clean + wellâ€‘labeled)
- target balance (% explicit)
- histograms + box/violinâ€‘style comparisons (where relevant)
- feature relationships vs target

### 3) Modeling pipeline (professional, replicable)
- train/test split
- preprocessing for numeric + categorical features (scaling + oneâ€‘hot)
- Logistic Regression model in a **scikitâ€‘learn Pipeline**

### 4) Advanced â€œWeekâ€‘6â€ evaluation visuals ğŸ“ˆ
- Confusion Matrix (thresholdâ€‘based)
- ROC curve + AUC (thresholdâ€‘free ranking)
- Precisionâ€‘Recall curve (imbalanceâ€‘friendly)
- Calibration curve (probability honesty)
- Threshold sweep plot (tradeoffs)
- Learning curve (data sufficiency / biasâ€‘variance signal)

### 5) Decision boundary / probability surface (visual intuition)
A clearer, more â€œwowâ€â€‘factor visualization showing how probability changes across the feature space.

---

## Repository contents ğŸ“¦
- `logisticalregression_enhanced.ipynb` â€” enhanced notebook (final)
- `spotify_tracks.csv` â€” dataset used by the notebook
- `requirements.txt` â€” reproducible Python dependencies

---

## Quickstart (Run locally) ğŸš€

### 1) Create and activate a virtual environment
**Windows (PowerShell)**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 2) Install dependencies
```bash
pip install -r requirements.txt
```

### 3) Launch Jupyter and run the notebook
```bash
jupyter notebook
```
Open:
- `logisticalregression_enhanced.ipynb`

> Tip: Keep `spotify_tracks.csv` in the **same folder** as the notebook for the cleanest run.

---

## Key talking points (presentationâ€‘ready) ğŸ—£ï¸
Use these when presenting:

1. **We turned real music metadata into a yes/no prediction problem**  
   The model learns patterns in popularity, duration, and genre to estimate *how likely a song is explicit*.

2. **Logistic Regression is perfect for Week 6 because itâ€™s explainable**  
   It gives probabilities, supports threshold tuning, and has an interpretable â€œlinear storyâ€ in the logâ€‘odds space.

3. **Accuracy alone can lie when classes are imbalanced**  
   Metrics like **logâ€‘loss**, **ROCâ€‘AUC**, and **PR curves** show whether the model is *useful* and *honest*.

---

## Replicability / Testing notes (profâ€‘proof) ğŸ§ª
- The notebook uses:
  - **scikitâ€‘learn Pipelines** to prevent data leakage
  - fixed `random_state` for consistent splits
  - consistent plotting and labeling conventions
- If results differ slightly:
  - confirm same package versions (`pip freeze`)
  - ensure the same CSV is used (no extra preprocessing outside notebook)

---

## Common troubleshooting ğŸ”§
- **FileNotFoundError for CSV**
  - Put `spotify_tracks.csv` next to the notebook
  - Or edit the notebook path cell to point to your local file location

- **Plots not showing**
  - Run the notebook topâ€‘toâ€‘bottom
  - Make sure youâ€™re using Jupyter Notebook/Lab (not a plain .py run)

---



---


